{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_random_sleep_ms': 1500, 'max_random_sleep_ms': 4000, 'max_requests_per_session': 100, 'data_path': 'data/hh_parsed_folder', 'search_resuests': ['data scientist', 'аналитик данных', 'machine learning', 'data engineer', 'data analyst']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class ParserConfig:\n",
    "    min_random_sleep_ms : int = 1500\n",
    "    max_random_sleep_ms : int = 4000\n",
    "    max_requests_per_session : int = 100\n",
    "    data_path = 'data/hh_parsed_folder'\n",
    "    search_resuests = ['data scientist', 'аналитик данных', 'machine learning', 'data engineer', 'data analyst']\n",
    "\n",
    "config_file_name = 'cnf/hh_parser.json'\n",
    "\n",
    "a = {\n",
    "    'min_random_sleep_ms' :  1500,\n",
    "    'max_random_sleep_ms' :  4000,\n",
    "    'max_requests_per_session' :  100,\n",
    "    'data_path' : 'data/hh_parsed_folder',\n",
    "    'search_resuests' : ['data scientist', 'аналитик данных', 'machine learning', 'data engineer', 'data analyst']\n",
    "}\n",
    "\n",
    "with open(config_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(a, f, ensure_ascii=False)\n",
    "\n",
    "with open(config_file_name, 'r', encoding='utf-8') as f:\n",
    "    xx = json.load(f)\n",
    "    print(xx)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"py/object\": \"__main__.ParserConfig\", \"min_random_sleep_ms\": 1500, \"max_random_sleep_ms\": 4000, \"max_requests_per_session\": 100, \"data_path\": \"data/hh_parsed_folder\", \"search_resuests\": [\"data scientist\", \"аналитик данных\", \"machine learning\", \"data engineer\", \"data analyst\"]}\n",
      "ParserConfig(min_random_sleep_ms=1500, max_random_sleep_ms=4000, max_requests_per_session=100, data_path='data/hh_parsed_folder', search_resuests=['data scientist', 'аналитик данных', 'machine learning', 'data engineer', 'data analyst'])\n"
     ]
    }
   ],
   "source": [
    "import jsonpickle\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class ParserConfig:\n",
    "    min_random_sleep_ms : int = 1500\n",
    "    max_random_sleep_ms : int = 4000\n",
    "    max_requests_per_session : int = 100\n",
    "    data_path : str = 'data/hh_parsed_folder'\n",
    "    search_resuests : List[str] = field(default_factory = lambda: (\n",
    "        ['data scientist', 'аналитик данных', 'machine learning', 'data engineer', 'data analyst']))\n",
    "\n",
    "config_file_name = 'cnf/hh_parser.json'\n",
    "\n",
    "a = ParserConfig()\n",
    "\n",
    "jsonpickle.set_preferred_backend('json')\n",
    "jsonpickle.set_encoder_options('json', ensure_ascii=False)\n",
    "\n",
    "with open(config_file_name, 'w', encoding='utf-8') as f:\n",
    "    print(jsonpickle.encode(a, ))\n",
    "    f.write(jsonpickle.encode(a))\n",
    "\n",
    "with open(config_file_name, 'r', encoding='utf-8') as f:\n",
    "    xx = jsonpickle.decode(f.read())\n",
    "    print(xx)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = {'search_period': 14,\n",
    "            'text': 'datascientist',\n",
    "            'ored_clusters': True,\n",
    "            'enable_snippets': True,\n",
    "            'clusters': True,\n",
    "            'area': 113,  # 113 - Russia\n",
    "            'hhtmFrom': 'vacancy_search_catalog',\n",
    "            'page': 1}\n",
    "\n",
    "sessia = requests.Session()\n",
    "\n",
    "req = sessia.get('https://hh.ru/search/vacancy?text=data+scientist', headers={'User-Agent': 'Custom'})\n",
    "\n",
    "with open('temp.html', 'w') as f:\n",
    "    f.write(req.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParserConfig(min_random_sleep_ms=1500, max_random_sleep_ms=123, max_requests_per_session=100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParserConfig(max_random_sleep_ms=123) or ParserConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver.maximize_window()\n",
    "driver.implicitly_wait(30)\n",
    "wait = WebDriverWait(driver, 30)\n",
    "driver.get(\"https://www.flashscore.com/football/albania/\")\n",
    "wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\"))).click()\n",
    "try:\n",
    "    wait.until(EC.presence_of_element_located((By.ID, \"live-table\")))\n",
    "    wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"section.event\")))\n",
    "    print(driver.page_source)\n",
    "finally:\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
